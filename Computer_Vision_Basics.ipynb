{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision_Basics (Solution)",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasperLS/toolbox/blob/main/Computer_Vision_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAmHZvUt9Ncx"
      },
      "source": [
        "## **Computer Vision Basics**\n",
        "\n",
        "This notebook covers multiple topics relevant for computer vision and machine learning preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYsW6Dr5FyTb"
      },
      "source": [
        "### **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwJpqiFJ84Oi"
      },
      "source": [
        "# import the modules \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Z99RiH__0c"
      },
      "source": [
        "\n",
        "# get an example\n",
        "from PIL import Image\n",
        "import requests\n",
        "im = Image.open(requests.get('https://images.unsplash.com/photo-1525697472245-fb8fd8594791?ixlib=rb-1.2.1&auto=format&fit=crop&w=2100&q=80', stream=True).raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srxxhw4EDNe1"
      },
      "source": [
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk40E6id4dlb"
      },
      "source": [
        "**What's an array?**\n",
        "\n",
        "Arrays in NumPy are multi-dimensional and can represent vectors, matrices, and images. An array is much like a list (or list of lists) but is restricted to having all elements of the same type. Unless specified on creation, the type will automatically be set depending on the data. After reading images to NumPy arrays, we can perform any mathematical operation we like on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlXt5INTAnAX"
      },
      "source": [
        "im = np.asarray(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w11BktEQA6wP"
      },
      "source": [
        "**What is an image from a machine's perspective?**\n",
        "\n",
        "They are defined as matrices of numbers representing the discrete color or intensity values present in every image pixel. Each image is considered as input data displayable in numerous ways, whether as arrays of pixel values or either multidimensional plots representing the distribution of pixel intensities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X2yEsF_A_IU"
      },
      "source": [
        "# can we still see the picture?\n",
        "plt.imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgrhVQ_4AQxW"
      },
      "source": [
        "# What are the dimensions of our image?\n",
        "print(im.shape)\n",
        "im.shape[0]*im.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOt2Ld66Awe0"
      },
      "source": [
        "### **Basic Annotations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHizuxxAvnd"
      },
      "source": [
        "# How can we crop the car?\n",
        "plt.imshow(im[900:,400:1750,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqnDvutCFK2c"
      },
      "source": [
        "# How can we mirror the picture on a vertical line?\n",
        "plt.imshow(im[:,::-1,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zFjFfxqEzzf"
      },
      "source": [
        "# How can we reverse color order?\n",
        "plt.imshow(im[:,:,::-1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2_px2YzFld6"
      },
      "source": [
        "# How can we rotate the image by 90 degrees?\n",
        "plt.imshow(np.swapaxes(im,0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DAuVOn7S3gU"
      },
      "source": [
        "### **Reverse Engineer Color Logic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKBke4ZS8m7"
      },
      "source": [
        "# Let's build an image, with 0s only\n",
        "new_im = np.zeros([100,100,3])\n",
        "new_im = new_im.astype(int)\n",
        "plt.imshow(new_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbQma5ncTOgX"
      },
      "source": [
        "# Let's make one color dimension = 100\n",
        "new_im[:,:,2] = int(255)\n",
        "plt.imshow(new_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyfXr9uoarTP"
      },
      "source": [
        "# Let's filter to one color channel only for our original image 'im'\n",
        "im_2 = im.copy()\n",
        "im_2[:,:,1:] = np.zeros([im.shape[0],im.shape[1],2])\n",
        "plt.imshow(im_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgxgd6riUzFA"
      },
      "source": [
        "# Let's mix green and red for new_im\n",
        "new_im[:,:,0] = int(255)\n",
        "new_im[:,:,1] = int(255)\n",
        "new_im[:,:,2] = int(0)\n",
        "plt.imshow(new_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEeM1hv_5jap"
      },
      "source": [
        "**Monochromic Images**\n",
        "\n",
        "Monochromic images only have one 'color' dimension, and may be used to represent all sorts of 2D data (e.g., heatmaps, terrain, maps)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE0Zh1rhcNzL"
      },
      "source": [
        "# For simplicity, let's only look at one of our color dimensions and create a grayscale image\n",
        "plt.imshow(np.average(im,axis=2),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcuxp0ifjGI"
      },
      "source": [
        "### **Playtime** \n",
        "\n",
        "Take the following code and create an artsy image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Ors_xfhHdt"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = np.zeros([100,100,3])\n",
        "image = image.astype(int)\n",
        "\n",
        "\n",
        "'''\n",
        "Your code: Feel free to use and combine any basic operations and numpy functions you want. \n",
        "You may also want to use loops.\n",
        "\n",
        "Once you are happy with your work, feel free to copy your picture and send it to:\n",
        "jasper dot schwenzow dot uni dash hamburg dot de.\n",
        "\n",
        "'''\n",
        "\n",
        "for i in range(80):\n",
        "  image[:,i,0] = np.linspace(50,255,100)\n",
        "  image[i,:,2] = np.linspace(50,255,100)\n",
        "\n",
        "for i in range(20,80):\n",
        "  image[:,i,0] = np.linspace(255,50,100)\n",
        "  image[i,:,2] = np.linspace(255,50,100)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMt7sfXWHXSq"
      },
      "source": [
        "### **Other Annotations Using cv2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKKj4s0p8EJe"
      },
      "source": [
        "**Image interpolation**\n",
        "\n",
        "It occurs when you resize or distort your image from one pixel grid to another. Image resizing is necessary when you need to increase or decrease the total number of pixels, whereas remapping can occur when you are correcting for lens distortion or rotating an image. Zooming refers to increase the quantity of pixels, so that when you zoom an image, you will see more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4opjirXuJPM"
      },
      "source": [
        "# let's get a random image\n",
        "np.random.seed(7)\n",
        "grid = np.random.rand(4,4)\n",
        "print(grid.shape)\n",
        "plt.imshow(grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0WzehzkvYdO"
      },
      "source": [
        "# how can we resize the image\n",
        "resized = cv2.resize(grid, (8,8), interpolation = cv2.INTER_CUBIC)\n",
        "resized.shape\n",
        "plt.imshow(resized)\n",
        "plt.show()\n",
        "plt.imshow(grid)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viZrMHmlJKOG"
      },
      "source": [
        "**Overview - Interpolations for plt.show()**\n",
        "\n",
        "To better see the differences in using different interpolations, the following example shows the changes due to interpolations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgG1BCMRFl34"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "methods = [None, 'none', 'nearest', 'bilinear', 'bicubic', 'spline16',\n",
        "           'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',\n",
        "           'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos']\n",
        "\n",
        "# Fixing random state for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "grid = np.random.rand(4, 4)\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=6, figsize=(9, 6),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "for ax, interp_method in zip(axs.flat, methods):\n",
        "    ax.imshow(grid, interpolation=interp_method, cmap='viridis')\n",
        "    ax.set_title(str(interp_method))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntOhyKZasb21"
      },
      "source": [
        "**Contrast Adjustment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDw6IClysfyJ"
      },
      "source": [
        "alpha = 2.0   # Contrast Control [1.0-3.0]\n",
        "beta = 0    # Brightness Control [0-100]\n",
        "\n",
        "# Scaling and converting the image contrast and brightness\n",
        "adjusted_image = cv2.convertScaleAbs(im, alpha=alpha, beta=beta)\n",
        "\n",
        "# Displaying the adusted image\n",
        "plt.imshow(adjusted_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GHFsqP6waNU"
      },
      "source": [
        "result_denoising = cv2.fastNlMeansDenoisingColored(im,None,20,10,7,21)\n",
        "plt.imshow(result_denoising)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg5f-RpEHopa"
      },
      "source": [
        "### **Kernel Operations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85x4_VGwkJe9"
      },
      "source": [
        "# let's take the grayscale image again\n",
        "gray = np.average(im,2)\n",
        "gray = cv2.resize(gray,(420,280))\n",
        "plt.imshow(gray,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl3g-6rIDZ1_"
      },
      "source": [
        "# Can we replicate the top sobel kernel?\n",
        "kernel = np.zeros((3,3))\n",
        "\n",
        "kernel[0,:] = 1*np.array([1,2,1])\n",
        "kernel[-1,:] = -1*np.array([1,2,1])\n",
        "print(kernel)\n",
        "\n",
        "im_2 = cv2.filter2D(gray, -1,kernel)\n",
        "cv2_imshow(im_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y3NCW3-ychH"
      },
      "source": [
        "# Let's get a smaller image and also fix RGB to BGR to use cv2_imshow\n",
        "im2 = cv2.resize(im[:,:,::-1], (420, 280))\n",
        "cv2_imshow(im2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFDJJbIDxWi"
      },
      "source": [
        "**Image Blurring (Image Smoothing)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbi2CtXg2aZb"
      },
      "source": [
        "# Can we get distorting blurriness??\n",
        "kernel = np.zeros((30,3))\n",
        "\n",
        "for i in range(30):\n",
        "  kernel[i,:] = 1*np.array([1,2,1])\n",
        "\n",
        "kernel = kernel/kernel.sum()\n",
        "\n",
        "im_kernel = cv2.filter2D(im2,-1,kernel)\n",
        "\n",
        "cv2_imshow(im_kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxe_V7fA40HR"
      },
      "source": [
        "# cv2 has some prebuild functions\n",
        "averaging_blur = cv2.blur(im2,(3,30))\n",
        "cv2_imshow(averaging_blur)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4LM_TEULs_z"
      },
      "source": [
        "# Gaussian blur\n",
        "gaussianblur_image = cv2.GaussianBlur(im2, (7,7), 0)\n",
        "cv2_imshow(gaussianblur_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q9-jyhEL568"
      },
      "source": [
        "# Median blur\n",
        "medianblur_image = cv2.medianBlur(im2,7)\n",
        "cv2_imshow(medianblur_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFYOqRiMtpJb"
      },
      "source": [
        "**Edge Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhJ5tyfo80Oj"
      },
      "source": [
        "edge_im = cv2.Canny(im2,100,200) # minVal and maxVal are the minimum and maximum intensity gradient values\n",
        "cv2_imshow(edge_im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cQEEiL_ud2l"
      },
      "source": [
        "**Histogram Equalization** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-HvLiIk4tXJ"
      },
      "source": [
        "It's used as a \"reference tool\" to make all images with same lighting conditions. For example, it is useful in face recognition, before training the face data, the images of faces are histogram equalized to make them all with same lighting conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWY-ap6yB3p"
      },
      "source": [
        "So, what's the goal? \n",
        "\n",
        "- Visualizing the set of lightness values for an image to improve the contrast of an image\n",
        "- A good image will have pixels from all regions of the image -> you need to strech the histogram to either ends \n",
        "- Real objective: To find an automated process to equally distribute light across the entire image without having to check area by area, pixel by pixel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J49_eeklyJYf"
      },
      "source": [
        "Step 1: Plotting a histogram showing intensity distribution by color channel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8PrwTQvRWxd"
      },
      "source": [
        "plt.imshow(im2[:,:,1])\n",
        "plt.show()\n",
        "plt.imshow(cv2.equalizeHist(im2[:,:,1]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fITZswiokWO"
      },
      "source": [
        "hist,bins = np.histogram(im2.flatten(),256,[0,256])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQWFYejwGLfA"
      },
      "source": [
        "cdf = hist.cumsum()\n",
        "float(hist.max()) / cdf.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehM5fXBjGRNN"
      },
      "source": [
        "cdf_normalized = cdf * float(hist.max()) / cdf.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfQk358q5gle"
      },
      "source": [
        "plt.plot(cdf_normalized, color = 'b')\n",
        "plt.hist(im2.flatten(),256,[0,256], color = 'r')\n",
        "plt.xlim([0,256])\n",
        "plt.legend(('cumulated distribution','color histogram'), loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w05CdMHc0acx"
      },
      "source": [
        "The Histogram shows that we do have abrupt variations in the range values.\n",
        "\n",
        "So now, we need a transformation function which maps the input pixels in brighter region to output pixels in full region (= histogram equalization).\n",
        "\n",
        "Step 2: We find the minimum histogram value (excluding 0) and apply the histogram equalization equation using the masked array concept array from Numpy. For masked array, all operations are performed on non-masked elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM0B6Vie236W"
      },
      "source": [
        "cdf_m = np.ma.masked_equal(cdf,0)\n",
        "cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
        "cdf = np.ma.filled(cdf_m,0).astype('uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCYXS8Pf3JoK"
      },
      "source": [
        "img2 = cdf[im2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VSf_s-M7PHV"
      },
      "source": [
        "Step 3: Plotting the new histogram and cdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXK39q032_Tr"
      },
      "source": [
        "hist,bins = np.histogram(img2.flatten(),256,[0,256])\n",
        "cdf = hist.cumsum()\n",
        "cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
        "plt.plot(cdf_normalized, color = 'b')\n",
        "plt.hist(img2.flatten(),256,[0,256], color = 'r')\n",
        "plt.xlim([0,256])\n",
        "plt.legend(('cumulated distribution','color histogram'), loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zvZBLDJ7U-Q"
      },
      "source": [
        "Step 4: Showing the \"new\" image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Wo1VAD3n10"
      },
      "source": [
        "cv2_imshow(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-bFZFAa8aVj"
      },
      "source": [
        "cv2_imshow(im2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}